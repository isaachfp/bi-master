{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_Uniform_to_Normal.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gifqzJaGoPXf"},"source":["#Generative Adversarial Network (GAN)\n","\n","Código base:\n","https://github.com/eriklindernoren/Keras-GAN\n","\n"]},{"cell_type":"code","metadata":{"id":"BZ2FNd3aoP2U"},"source":["#Carregar bibliotecas\n","from keras.layers import Input, Dense, Reshape, BatchNormalization\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","# Seed para reprodução de resultados\n","seed = 10\n","random.seed(seed)\n","np.random.seed(seed)\n","import tensorflow as tf\n","tf.random.set_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wy7TiU7RFpZ1"},"source":["input_shape = (500,)\n","latent_dim = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gQ3-itTP3dDg"},"source":["#gerar dados de entrada com distribuição uniforme\n","import pandas as pd\n","X = pd.DataFrame(np.random.uniform(0,1,size=(10000, latent_dim)))\n","X.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENVtDqiLikVM"},"source":["#distribuicao para amostra\n","linha1 = X.iloc[1,:]\n","histogram_i = plt.hist(linha1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-xYPfLRJvSwM"},"source":["###Exercício 1: Gerar dados com distbuição normal. Salvar em uma variável chamada 'y'. Plotar o histograma. Imprimir a média e o desvio de uma amostra qualquer."]},{"cell_type":"code","metadata":{"id":"KZAf5I9tjVld"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dqLLthtB1Rul"},"source":["# Criar o Gerador\n","generator = Sequential()\n","\n","generator.add(Dense(256, input_dim=latent_dim))\n","generator.add(LeakyReLU(alpha=0.2))\n","generator.add(BatchNormalization(momentum=0.8))\n","\n","generator.add(Dense(512))\n","generator.add(LeakyReLU(alpha=0.2))\n","generator.add(BatchNormalization(momentum=0.8))\n","\n","generator.add(Dense(1024))\n","generator.add(LeakyReLU(alpha=0.2))\n","generator.add(BatchNormalization(momentum=0.8))\n","\n","generator.add(Dense(np.prod(input_shape), activation='linear'))\n","generator.add(Reshape(input_shape))\n","generator.summary()\n","\n","noise = Input(shape=(latent_dim,))\n","distribution = generator(noise)\n","generator = Model(noise, distribution)\n","\n","# Compilar o gerador\n","optimizer = Adam(0.0002, 0.5)\n","generator.compile(loss='binary_crossentropy', optimizer=optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpf2jXBu0yiO"},"source":["# Criar o Discriminador\n","discriminator = Sequential()\n","\n","discriminator.add(Dense(512, input_shape=input_shape))\n","discriminator.add(LeakyReLU(alpha=0.2))\n","\n","discriminator.add(Dense(256))\n","discriminator.add(LeakyReLU(alpha=0.2))\n","\n","discriminator.add(Dense(1, activation='sigmoid'))\n","discriminator.summary()\n","\n","distribution = Input(shape=input_shape)\n","validity = discriminator(distribution)\n","discriminator = Model(distribution, validity)\n","\n","# Compilar o discriminador\n","discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnZ38ep3W862"},"source":["# O gerador recebe um ruído como entrada e gera a amostra com a distribuição aprendida\n","input = Input(shape=(latent_dim,))\n","gen_data = generator(input)\n","validity = discriminator(gen_data)\n","\n","# Para o modelo combinado, somente treinaremos o gerador\n","discriminator.trainable = False\n","\n","# Modelo combinado: stacked generator and discriminator\n","# Treina o gerador para enganar o discriminador\n","combined = Model(input, validity)\n","combined.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","# Mostrar a estrutura do modelo criado\n","config = combined.get_config()\n","model = Model.from_config(config)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_QfPKBLr-lNW"},"source":["def sample_images(epoch):\r\n","  r, c = 5, 5\r\n","  noise = np.random.uniform(0, 1, (r * c, latent_dim))\r\n","  gen_imgs = generator.predict(noise)\r\n","\r\n","  # Rescale images 0 - 1\r\n","  gen_imgs = 0.5 * gen_imgs + 0.5\r\n","\r\n","  fig, axs = plt.subplots(r, c)\r\n","  cnt = 0\r\n","  for i in range(r):\r\n","      for j in range(c):\r\n","          axs[i,j].hist(gen_imgs[cnt, :])\r\n","          axs[i,j].axis('off')\r\n","          # axs[i,j].set_title(epoch)\r\n","          fig.suptitle(epoch)\r\n","          cnt += 1\r\n","  plt.subplots(r, c)\r\n","  plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3ZCmZqGK_GP"},"source":["batch_size=32\n","epochs=1200\n","sample_interval=200\n","\n","# history\n","d_loss_history = []\n","d_acc_history = []\n","d_acc_real_history = []\n","d_acc_fake_history = []\n","g_loss_history = []\n","g_acc_history = []\n","\n","# Vetores com 0s e 1s indicando, respectivamente, amostras fakes e reais\n","valid = np.ones((batch_size, 1))\n","fake = np.zeros((batch_size, 1))\n","\n","for epoch in range(epochs):\n","\n","# ---------------------\n","#  Treina o Discriminador\n","# ---------------------\n","# Seleciona um batch aleatório de dados\n","  idx = np.random.randint(0, len(X[1]), batch_size)\n","  imgs = y.iloc[idx,:]\n","  noise = X.iloc[idx,:]\n","\n","  # Gera um batch de novos dados\n","  gen_imgs = generator.predict(noise)\n","\n","  # Treina o discriminador\n","  d_loss_real = discriminator.train_on_batch(imgs, valid)\n","  d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n","  d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","  d_loss_history.append(d_loss[0])\n","  d_acc_history.append(d_loss[1])\n","  d_acc_real_history.append(d_loss_real[1])\n","  d_acc_fake_history.append(d_loss_fake[1])\n","\n","  # ---------------------\n","  #  Treina o Gerador\n","  # ---------------------\n","\n","  # Treina o gerador para que faça o discriminador classificar os dados criados como reais\n","  g_loss, g_acc = combined.train_on_batch(noise, valid)\n","\n","  g_loss_history.append(g_loss)\n","  g_acc_history.append(g_acc)\n","  \n","  # Progresso\n","  print (\"%d [D loss: %f, accDreal.: %.2f%%, accDfake.: %.2f%%] [G loss: %f, accG.: %.2f%%]\" % (epoch, d_loss[0], 100*d_loss_real[1], 100*d_loss_fake[1], g_loss, 100*g_acc))\n","\n","  # Gerar imagens ao longo do treinamento\n","  if epoch % sample_interval == 0:\n","    sample_images(epoch)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eu_3x-ws-uCC"},"source":["# Gráfico da evolução do erro e da acurácia\r\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,4))\r\n","ax1.plot(d_loss_history, label='discriminador')\r\n","ax1.plot(g_loss_history, label='gerador')\r\n","ax1.set_title('Loss')\r\n","ax1.set_xlabel('época')\r\n","ax1.set_ylabel('loss')\r\n","ax1.legend()\r\n","\r\n","ax2.plot(d_acc_history, label='discriminador')\r\n","ax2.plot(g_acc_history, label='gerador')\r\n","ax2.set_title('Acurácia')\r\n","ax2.set_xlabel('época')\r\n","ax2.set_ylabel('acurácia')\r\n","ax2.legend()\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WoCw3Uef-wea"},"source":["plt.plot(d_acc_real_history, label='real')\r\n","plt.plot(d_acc_fake_history, label='fake')\r\n","plt.title('Acurácia Discriminador')\r\n","plt.xlabel('época')\r\n","plt.ylabel('acurácia')\r\n","plt.legend()\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"duKaIlwrvpSL"},"source":["###Exercício 2: Criar uma amostra para teste. Visualizar a base (função head())"]},{"cell_type":"code","metadata":{"id":"i7jwgEPnH94t"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LDUfbXViv2p8"},"source":["###Exercício 3: visualizar algumas características da base através da função describe()"]},{"cell_type":"code","metadata":{"id":"t0K-x72Zsgxm"},"source":["#por coluna. Aproximadamente a mesma distribuiçao que criamos por linha\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MJ8H2BmAwFAB"},"source":["###Exercicio 4: plotar o histograma da base de teste (ruído) gerada"]},{"cell_type":"code","metadata":{"id":"1_-Y9LMKs3o-"},"source":["#distribuicao: primeira linha"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U97t-4niwOKo"},"source":["###Exercício 5: Utilizar a GAN treinada para gerar dados com a distribuição desejada"]},{"cell_type":"code","metadata":{"id":"0vwrsjdTNvQi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fGgT3FrNwWQz"},"source":["###Exercício 6: plotar o histograma da distribuição dos dados gerados pela GAN"]},{"cell_type":"code","metadata":{"id":"zTC7KkNYErWX"},"source":[""],"execution_count":null,"outputs":[]}]}