{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_Uniform_to_Normal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaachfp/bi-master/blob/master/ADI/20210126_GAN_Uniform_to_Normal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gifqzJaGoPXf"
      },
      "source": [
        "#Generative Adversarial Network (GAN)\n",
        "\n",
        "Código base:\n",
        "https://github.com/eriklindernoren/Keras-GAN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ2FNd3aoP2U"
      },
      "source": [
        " ##Carregar bibliotecas\n",
        "from keras.layers import Input, Dense, Reshape, BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "# Seed para reprodução de resultados\n",
        "seed = 10\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy7TiU7RFpZ1"
      },
      "source": [
        "input_shape = (500,)\n",
        "latent_dim = 100 # limitar o gerador"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ3-itTP3dDg",
        "outputId": "12483cf7-689a-4571-b8c6-4a3a5dd1dbe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "#gerar dados de entrada com distribuição uniforme\n",
        "import pandas as pd\n",
        "X = pd.DataFrame(np.random.uniform(0,1,size=(10000, latent_dim)))\n",
        "X.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.771321</td>\n",
              "      <td>0.020752</td>\n",
              "      <td>0.633648</td>\n",
              "      <td>0.748804</td>\n",
              "      <td>0.498507</td>\n",
              "      <td>0.224797</td>\n",
              "      <td>0.198063</td>\n",
              "      <td>0.760531</td>\n",
              "      <td>0.169111</td>\n",
              "      <td>0.088340</td>\n",
              "      <td>0.685360</td>\n",
              "      <td>0.953393</td>\n",
              "      <td>0.003948</td>\n",
              "      <td>0.512192</td>\n",
              "      <td>0.812621</td>\n",
              "      <td>0.612526</td>\n",
              "      <td>0.721755</td>\n",
              "      <td>0.291876</td>\n",
              "      <td>0.917774</td>\n",
              "      <td>0.714576</td>\n",
              "      <td>0.542544</td>\n",
              "      <td>0.142170</td>\n",
              "      <td>0.373341</td>\n",
              "      <td>0.674134</td>\n",
              "      <td>0.441833</td>\n",
              "      <td>0.434014</td>\n",
              "      <td>0.617767</td>\n",
              "      <td>0.513138</td>\n",
              "      <td>0.650397</td>\n",
              "      <td>0.601039</td>\n",
              "      <td>0.805223</td>\n",
              "      <td>0.521647</td>\n",
              "      <td>0.908649</td>\n",
              "      <td>0.319236</td>\n",
              "      <td>0.090459</td>\n",
              "      <td>0.300700</td>\n",
              "      <td>0.113984</td>\n",
              "      <td>0.828681</td>\n",
              "      <td>0.046896</td>\n",
              "      <td>0.626287</td>\n",
              "      <td>...</td>\n",
              "      <td>0.597372</td>\n",
              "      <td>0.902832</td>\n",
              "      <td>0.534558</td>\n",
              "      <td>0.590201</td>\n",
              "      <td>0.039282</td>\n",
              "      <td>0.357182</td>\n",
              "      <td>0.079613</td>\n",
              "      <td>0.305460</td>\n",
              "      <td>0.330719</td>\n",
              "      <td>0.773830</td>\n",
              "      <td>0.039959</td>\n",
              "      <td>0.429492</td>\n",
              "      <td>0.314927</td>\n",
              "      <td>0.636491</td>\n",
              "      <td>0.346347</td>\n",
              "      <td>0.043097</td>\n",
              "      <td>0.879915</td>\n",
              "      <td>0.763241</td>\n",
              "      <td>0.878097</td>\n",
              "      <td>0.417509</td>\n",
              "      <td>0.605578</td>\n",
              "      <td>0.513467</td>\n",
              "      <td>0.597837</td>\n",
              "      <td>0.262216</td>\n",
              "      <td>0.300871</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.303063</td>\n",
              "      <td>0.242076</td>\n",
              "      <td>0.557578</td>\n",
              "      <td>0.565507</td>\n",
              "      <td>0.475132</td>\n",
              "      <td>0.292798</td>\n",
              "      <td>0.064251</td>\n",
              "      <td>0.978819</td>\n",
              "      <td>0.339708</td>\n",
              "      <td>0.495049</td>\n",
              "      <td>0.977081</td>\n",
              "      <td>0.440774</td>\n",
              "      <td>0.318273</td>\n",
              "      <td>0.519797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.578136</td>\n",
              "      <td>0.853934</td>\n",
              "      <td>0.068097</td>\n",
              "      <td>0.464531</td>\n",
              "      <td>0.781949</td>\n",
              "      <td>0.718603</td>\n",
              "      <td>0.586022</td>\n",
              "      <td>0.037094</td>\n",
              "      <td>0.350656</td>\n",
              "      <td>0.563191</td>\n",
              "      <td>0.299730</td>\n",
              "      <td>0.512334</td>\n",
              "      <td>0.673467</td>\n",
              "      <td>0.159194</td>\n",
              "      <td>0.050478</td>\n",
              "      <td>0.337816</td>\n",
              "      <td>0.108064</td>\n",
              "      <td>0.178903</td>\n",
              "      <td>0.885827</td>\n",
              "      <td>0.365365</td>\n",
              "      <td>0.218769</td>\n",
              "      <td>0.752496</td>\n",
              "      <td>0.106880</td>\n",
              "      <td>0.744603</td>\n",
              "      <td>0.469785</td>\n",
              "      <td>0.598256</td>\n",
              "      <td>0.147620</td>\n",
              "      <td>0.184035</td>\n",
              "      <td>0.645072</td>\n",
              "      <td>0.048628</td>\n",
              "      <td>0.248613</td>\n",
              "      <td>0.542409</td>\n",
              "      <td>0.226773</td>\n",
              "      <td>0.381412</td>\n",
              "      <td>0.922233</td>\n",
              "      <td>0.925357</td>\n",
              "      <td>0.566750</td>\n",
              "      <td>0.533471</td>\n",
              "      <td>0.014860</td>\n",
              "      <td>0.977899</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295904</td>\n",
              "      <td>0.037558</td>\n",
              "      <td>0.030685</td>\n",
              "      <td>0.453105</td>\n",
              "      <td>0.744864</td>\n",
              "      <td>0.557295</td>\n",
              "      <td>0.385114</td>\n",
              "      <td>0.168073</td>\n",
              "      <td>0.838261</td>\n",
              "      <td>0.599052</td>\n",
              "      <td>0.782715</td>\n",
              "      <td>0.848509</td>\n",
              "      <td>0.603163</td>\n",
              "      <td>0.781061</td>\n",
              "      <td>0.615737</td>\n",
              "      <td>0.021165</td>\n",
              "      <td>0.750465</td>\n",
              "      <td>0.176042</td>\n",
              "      <td>0.458514</td>\n",
              "      <td>0.513123</td>\n",
              "      <td>0.484021</td>\n",
              "      <td>0.844386</td>\n",
              "      <td>0.174814</td>\n",
              "      <td>0.014635</td>\n",
              "      <td>0.848764</td>\n",
              "      <td>0.742675</td>\n",
              "      <td>0.456698</td>\n",
              "      <td>0.416898</td>\n",
              "      <td>0.116730</td>\n",
              "      <td>0.338679</td>\n",
              "      <td>0.094659</td>\n",
              "      <td>0.715831</td>\n",
              "      <td>0.077085</td>\n",
              "      <td>0.205950</td>\n",
              "      <td>0.573776</td>\n",
              "      <td>0.293832</td>\n",
              "      <td>0.655727</td>\n",
              "      <td>0.803568</td>\n",
              "      <td>0.351214</td>\n",
              "      <td>0.093440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.813316</td>\n",
              "      <td>0.784867</td>\n",
              "      <td>0.393419</td>\n",
              "      <td>0.864479</td>\n",
              "      <td>0.384031</td>\n",
              "      <td>0.257303</td>\n",
              "      <td>0.829402</td>\n",
              "      <td>0.736383</td>\n",
              "      <td>0.507601</td>\n",
              "      <td>0.644327</td>\n",
              "      <td>0.213187</td>\n",
              "      <td>0.895709</td>\n",
              "      <td>0.965946</td>\n",
              "      <td>0.317002</td>\n",
              "      <td>0.865553</td>\n",
              "      <td>0.310284</td>\n",
              "      <td>0.025264</td>\n",
              "      <td>0.049195</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.069033</td>\n",
              "      <td>0.257475</td>\n",
              "      <td>0.913582</td>\n",
              "      <td>0.457850</td>\n",
              "      <td>0.130212</td>\n",
              "      <td>0.809892</td>\n",
              "      <td>0.403470</td>\n",
              "      <td>0.024433</td>\n",
              "      <td>0.856831</td>\n",
              "      <td>0.274295</td>\n",
              "      <td>0.709106</td>\n",
              "      <td>0.355772</td>\n",
              "      <td>0.794309</td>\n",
              "      <td>0.844619</td>\n",
              "      <td>0.538148</td>\n",
              "      <td>0.559087</td>\n",
              "      <td>0.122510</td>\n",
              "      <td>0.377642</td>\n",
              "      <td>0.428747</td>\n",
              "      <td>0.511209</td>\n",
              "      <td>0.891763</td>\n",
              "      <td>...</td>\n",
              "      <td>0.263403</td>\n",
              "      <td>0.122336</td>\n",
              "      <td>0.458724</td>\n",
              "      <td>0.974812</td>\n",
              "      <td>0.680574</td>\n",
              "      <td>0.193254</td>\n",
              "      <td>0.046739</td>\n",
              "      <td>0.952644</td>\n",
              "      <td>0.858649</td>\n",
              "      <td>0.827903</td>\n",
              "      <td>0.963901</td>\n",
              "      <td>0.598936</td>\n",
              "      <td>0.930916</td>\n",
              "      <td>0.146769</td>\n",
              "      <td>0.113960</td>\n",
              "      <td>0.372029</td>\n",
              "      <td>0.766560</td>\n",
              "      <td>0.321142</td>\n",
              "      <td>0.638035</td>\n",
              "      <td>0.009221</td>\n",
              "      <td>0.543465</td>\n",
              "      <td>0.337755</td>\n",
              "      <td>0.898024</td>\n",
              "      <td>0.940707</td>\n",
              "      <td>0.384122</td>\n",
              "      <td>0.396118</td>\n",
              "      <td>0.897280</td>\n",
              "      <td>0.058822</td>\n",
              "      <td>0.405379</td>\n",
              "      <td>0.130176</td>\n",
              "      <td>0.086969</td>\n",
              "      <td>0.783964</td>\n",
              "      <td>0.304573</td>\n",
              "      <td>0.584056</td>\n",
              "      <td>0.878466</td>\n",
              "      <td>0.880792</td>\n",
              "      <td>0.600954</td>\n",
              "      <td>0.645228</td>\n",
              "      <td>0.056628</td>\n",
              "      <td>0.297484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.691775</td>\n",
              "      <td>0.189029</td>\n",
              "      <td>0.803008</td>\n",
              "      <td>0.514764</td>\n",
              "      <td>0.757286</td>\n",
              "      <td>0.177789</td>\n",
              "      <td>0.082620</td>\n",
              "      <td>0.482072</td>\n",
              "      <td>0.528854</td>\n",
              "      <td>0.696308</td>\n",
              "      <td>0.204762</td>\n",
              "      <td>0.671372</td>\n",
              "      <td>0.793269</td>\n",
              "      <td>0.041738</td>\n",
              "      <td>0.963358</td>\n",
              "      <td>0.975393</td>\n",
              "      <td>0.550661</td>\n",
              "      <td>0.064907</td>\n",
              "      <td>0.345237</td>\n",
              "      <td>0.020430</td>\n",
              "      <td>0.800852</td>\n",
              "      <td>0.207927</td>\n",
              "      <td>0.143253</td>\n",
              "      <td>0.699894</td>\n",
              "      <td>0.057950</td>\n",
              "      <td>0.256608</td>\n",
              "      <td>0.510332</td>\n",
              "      <td>0.995259</td>\n",
              "      <td>0.146516</td>\n",
              "      <td>0.449515</td>\n",
              "      <td>0.601440</td>\n",
              "      <td>0.097272</td>\n",
              "      <td>0.288735</td>\n",
              "      <td>0.720800</td>\n",
              "      <td>0.550806</td>\n",
              "      <td>0.838577</td>\n",
              "      <td>0.580331</td>\n",
              "      <td>0.184572</td>\n",
              "      <td>0.615502</td>\n",
              "      <td>0.886955</td>\n",
              "      <td>...</td>\n",
              "      <td>0.087493</td>\n",
              "      <td>0.116879</td>\n",
              "      <td>0.771071</td>\n",
              "      <td>0.732795</td>\n",
              "      <td>0.087128</td>\n",
              "      <td>0.357463</td>\n",
              "      <td>0.773212</td>\n",
              "      <td>0.131472</td>\n",
              "      <td>0.537832</td>\n",
              "      <td>0.754724</td>\n",
              "      <td>0.272526</td>\n",
              "      <td>0.566517</td>\n",
              "      <td>0.476685</td>\n",
              "      <td>0.556621</td>\n",
              "      <td>0.440737</td>\n",
              "      <td>0.693737</td>\n",
              "      <td>0.718237</td>\n",
              "      <td>0.756382</td>\n",
              "      <td>0.037322</td>\n",
              "      <td>0.678835</td>\n",
              "      <td>0.477221</td>\n",
              "      <td>0.100171</td>\n",
              "      <td>0.614196</td>\n",
              "      <td>0.837915</td>\n",
              "      <td>0.733894</td>\n",
              "      <td>0.321566</td>\n",
              "      <td>0.067855</td>\n",
              "      <td>0.037330</td>\n",
              "      <td>0.559125</td>\n",
              "      <td>0.160853</td>\n",
              "      <td>0.267888</td>\n",
              "      <td>0.235712</td>\n",
              "      <td>0.019347</td>\n",
              "      <td>0.151686</td>\n",
              "      <td>0.033903</td>\n",
              "      <td>0.981835</td>\n",
              "      <td>0.360485</td>\n",
              "      <td>0.825465</td>\n",
              "      <td>0.412237</td>\n",
              "      <td>0.253179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.236711</td>\n",
              "      <td>0.773116</td>\n",
              "      <td>0.671257</td>\n",
              "      <td>0.706331</td>\n",
              "      <td>0.853155</td>\n",
              "      <td>0.522050</td>\n",
              "      <td>0.442770</td>\n",
              "      <td>0.553748</td>\n",
              "      <td>0.651995</td>\n",
              "      <td>0.788554</td>\n",
              "      <td>0.892269</td>\n",
              "      <td>0.309105</td>\n",
              "      <td>0.135610</td>\n",
              "      <td>0.750927</td>\n",
              "      <td>0.526833</td>\n",
              "      <td>0.784739</td>\n",
              "      <td>0.429926</td>\n",
              "      <td>0.838847</td>\n",
              "      <td>0.537354</td>\n",
              "      <td>0.250424</td>\n",
              "      <td>0.058894</td>\n",
              "      <td>0.091949</td>\n",
              "      <td>0.174200</td>\n",
              "      <td>0.439254</td>\n",
              "      <td>0.810934</td>\n",
              "      <td>0.910402</td>\n",
              "      <td>0.576091</td>\n",
              "      <td>0.291154</td>\n",
              "      <td>0.651786</td>\n",
              "      <td>0.637921</td>\n",
              "      <td>0.503575</td>\n",
              "      <td>0.965553</td>\n",
              "      <td>0.806691</td>\n",
              "      <td>0.928519</td>\n",
              "      <td>0.613935</td>\n",
              "      <td>0.982004</td>\n",
              "      <td>0.714988</td>\n",
              "      <td>0.008659</td>\n",
              "      <td>0.288146</td>\n",
              "      <td>0.841399</td>\n",
              "      <td>...</td>\n",
              "      <td>0.279090</td>\n",
              "      <td>0.120680</td>\n",
              "      <td>0.480688</td>\n",
              "      <td>0.932302</td>\n",
              "      <td>0.914927</td>\n",
              "      <td>0.243875</td>\n",
              "      <td>0.394858</td>\n",
              "      <td>0.970240</td>\n",
              "      <td>0.275620</td>\n",
              "      <td>0.937849</td>\n",
              "      <td>0.769012</td>\n",
              "      <td>0.884719</td>\n",
              "      <td>0.871005</td>\n",
              "      <td>0.146471</td>\n",
              "      <td>0.789189</td>\n",
              "      <td>0.909222</td>\n",
              "      <td>0.838171</td>\n",
              "      <td>0.712031</td>\n",
              "      <td>0.307379</td>\n",
              "      <td>0.353785</td>\n",
              "      <td>0.236353</td>\n",
              "      <td>0.089812</td>\n",
              "      <td>0.194478</td>\n",
              "      <td>0.615808</td>\n",
              "      <td>0.932084</td>\n",
              "      <td>0.691084</td>\n",
              "      <td>0.562847</td>\n",
              "      <td>0.263756</td>\n",
              "      <td>0.527147</td>\n",
              "      <td>0.804383</td>\n",
              "      <td>0.295076</td>\n",
              "      <td>0.183339</td>\n",
              "      <td>0.019732</td>\n",
              "      <td>0.743321</td>\n",
              "      <td>0.038293</td>\n",
              "      <td>0.433680</td>\n",
              "      <td>0.832085</td>\n",
              "      <td>0.013459</td>\n",
              "      <td>0.509335</td>\n",
              "      <td>0.479549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        97        98        99\n",
              "0  0.771321  0.020752  0.633648  ...  0.440774  0.318273  0.519797\n",
              "1  0.578136  0.853934  0.068097  ...  0.803568  0.351214  0.093440\n",
              "2  0.813316  0.784867  0.393419  ...  0.645228  0.056628  0.297484\n",
              "3  0.691775  0.189029  0.803008  ...  0.825465  0.412237  0.253179\n",
              "4  0.236711  0.773116  0.671257  ...  0.013459  0.509335  0.479549\n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENVtDqiLikVM",
        "outputId": "d43b6e3d-7ca7-4896-f950-a99ca37ae268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#distribuicao para amostra\n",
        "linha1 = X.iloc[1,:]\n",
        "histogram_i = plt.hist(linha1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xYPfLRJvSwM"
      },
      "source": [
        "###Exercício 1: Gerar dados com distbuição normal. Salvar em uma variável chamada 'y'. Plotar o histograma. Imprimir a média e o desvio de uma amostra qualquer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZAf5I9tjVld"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqLLthtB1Rul"
      },
      "source": [
        "# Criar o Gerador\n",
        "generator = Sequential()\n",
        "\n",
        "generator.add(Dense(256, input_dim=latent_dim))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "generator.add(Dense(512))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "generator.add(Dense(1024))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "generator.add(Dense(np.prod(input_shape), activation='linear'))\n",
        "generator.add(Reshape(input_shape))\n",
        "generator.summary()\n",
        "\n",
        "noise = Input(shape=(latent_dim,))\n",
        "distribution = generator(noise)\n",
        "generator = Model(noise, distribution)\n",
        "\n",
        "# Compilar o gerador\n",
        "optimizer = Adam(0.0002, 0.5)\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpf2jXBu0yiO"
      },
      "source": [
        "# Criar o Discriminador\n",
        "discriminator = Sequential()\n",
        "\n",
        "discriminator.add(Dense(512, input_shape=input_shape))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "discriminator.add(Dense(256))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "discriminator.add(Dense(1, activation='sigmoid'))\n",
        "discriminator.summary()\n",
        "\n",
        "distribution = Input(shape=input_shape)\n",
        "validity = discriminator(distribution)\n",
        "discriminator = Model(distribution, validity)\n",
        "\n",
        "# Compilar o discriminador\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnZ38ep3W862"
      },
      "source": [
        "# O gerador recebe um ruído como entrada e gera a amostra com a distribuição aprendida\n",
        "input = Input(shape=(latent_dim,))\n",
        "gen_data = generator(input)\n",
        "validity = discriminator(gen_data)\n",
        "\n",
        "# Para o modelo combinado, somente treinaremos o gerador\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Modelo combinado: stacked generator and discriminator\n",
        "# Treina o gerador para enganar o discriminador\n",
        "combined = Model(input, validity)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Mostrar a estrutura do modelo criado\n",
        "config = combined.get_config()\n",
        "model = Model.from_config(config)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QfPKBLr-lNW"
      },
      "source": [
        "def sample_images(epoch):\r\n",
        "  r, c = 5, 5\r\n",
        "  noise = np.random.uniform(0, 1, (r * c, latent_dim))\r\n",
        "  gen_imgs = generator.predict(noise)\r\n",
        "\r\n",
        "  # Rescale images 0 - 1\r\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\r\n",
        "\r\n",
        "  fig, axs = plt.subplots(r, c)\r\n",
        "  cnt = 0\r\n",
        "  for i in range(r):\r\n",
        "      for j in range(c):\r\n",
        "          axs[i,j].hist(gen_imgs[cnt, :])\r\n",
        "          axs[i,j].axis('off')\r\n",
        "          # axs[i,j].set_title(epoch)\r\n",
        "          fig.suptitle(epoch)\r\n",
        "          cnt += 1\r\n",
        "  plt.subplots(r, c)\r\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3ZCmZqGK_GP"
      },
      "source": [
        "batch_size=32\n",
        "epochs=1200\n",
        "sample_interval=200\n",
        "\n",
        "# history\n",
        "d_loss_history = []\n",
        "d_acc_history = []\n",
        "d_acc_real_history = []\n",
        "d_acc_fake_history = []\n",
        "g_loss_history = []\n",
        "g_acc_history = []\n",
        "\n",
        "# Vetores com 0s e 1s indicando, respectivamente, amostras fakes e reais\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "# ---------------------\n",
        "#  Treina o Discriminador\n",
        "# ---------------------\n",
        "# Seleciona um batch aleatório de dados\n",
        "  idx = np.random.randint(0, len(X[1]), batch_size)\n",
        "  imgs = y.iloc[idx,:]\n",
        "  noise = X.iloc[idx,:]\n",
        "\n",
        "  # Gera um batch de novos dados\n",
        "  gen_imgs = generator.predict(noise)\n",
        "\n",
        "  # Treina o discriminador\n",
        "  d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "  d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "  d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "  d_loss_history.append(d_loss[0])\n",
        "  d_acc_history.append(d_loss[1])\n",
        "  d_acc_real_history.append(d_loss_real[1])\n",
        "  d_acc_fake_history.append(d_loss_fake[1])\n",
        "\n",
        "  # ---------------------\n",
        "  #  Treina o Gerador\n",
        "  # ---------------------\n",
        "\n",
        "  # Treina o gerador para que faça o discriminador classificar os dados criados como reais\n",
        "  g_loss, g_acc = combined.train_on_batch(noise, valid)\n",
        "\n",
        "  g_loss_history.append(g_loss)\n",
        "  g_acc_history.append(g_acc)\n",
        "  \n",
        "  # Progresso\n",
        "  print (\"%d [D loss: %f, accDreal.: %.2f%%, accDfake.: %.2f%%] [G loss: %f, accG.: %.2f%%]\" % (epoch, d_loss[0], 100*d_loss_real[1], 100*d_loss_fake[1], g_loss, 100*g_acc))\n",
        "\n",
        "  # Gerar imagens ao longo do treinamento\n",
        "  if epoch % sample_interval == 0:\n",
        "    sample_images(epoch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu_3x-ws-uCC"
      },
      "source": [
        "# Gráfico da evolução do erro e da acurácia\r\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,4))\r\n",
        "ax1.plot(d_loss_history, label='discriminador')\r\n",
        "ax1.plot(g_loss_history, label='gerador')\r\n",
        "ax1.set_title('Loss')\r\n",
        "ax1.set_xlabel('época')\r\n",
        "ax1.set_ylabel('loss')\r\n",
        "ax1.legend()\r\n",
        "\r\n",
        "ax2.plot(d_acc_history, label='discriminador')\r\n",
        "ax2.plot(g_acc_history, label='gerador')\r\n",
        "ax2.set_title('Acurácia')\r\n",
        "ax2.set_xlabel('época')\r\n",
        "ax2.set_ylabel('acurácia')\r\n",
        "ax2.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoCw3Uef-wea"
      },
      "source": [
        "plt.plot(d_acc_real_history, label='real')\r\n",
        "plt.plot(d_acc_fake_history, label='fake')\r\n",
        "plt.title('Acurácia Discriminador')\r\n",
        "plt.xlabel('época')\r\n",
        "plt.ylabel('acurácia')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duKaIlwrvpSL"
      },
      "source": [
        "###Exercício 2: Criar uma amostra para teste. Visualizar a base (função head())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7jwgEPnH94t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDUfbXViv2p8"
      },
      "source": [
        "###Exercício 3: visualizar algumas características da base através da função describe()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0K-x72Zsgxm"
      },
      "source": [
        "#por coluna. Aproximadamente a mesma distribuiçao que criamos por linha\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ8H2BmAwFAB"
      },
      "source": [
        "###Exercicio 4: plotar o histograma da base de teste (ruído) gerada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_-Y9LMKs3o-"
      },
      "source": [
        "#distribuicao: primeira linha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U97t-4niwOKo"
      },
      "source": [
        "###Exercício 5: Utilizar a GAN treinada para gerar dados com a distribuição desejada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vwrsjdTNvQi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgT3FrNwWQz"
      },
      "source": [
        "###Exercício 6: plotar o histograma da distribuição dos dados gerados pela GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTC7KkNYErWX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}